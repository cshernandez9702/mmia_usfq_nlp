{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Lab transformers"
      ],
      "metadata": {
        "id": "2bws52v3QHix"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-Gf2Vc4aQah9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Felipe Toscano\n",
        "- Christian Hernandez"
      ],
      "metadata": {
        "id": "WU4VHDfjQOec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "import requests\n",
        "import unicodedata\n",
        "import re\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "# Configuración del dispositivo (GPU si está disponible)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Usando dispositivo: {device}\")\n",
        "\n",
        "# Parámetro de longitud máxima para las secuencias\n",
        "MAX_LENGTH = 10\n",
        "\n",
        "# Descarga del conjunto de datos desde la URL y guardado localmente\n",
        "url = \"https://raw.githubusercontent.com/aproano2/mmia-6021-fall24/main/guides/data/spa.txt\"\n",
        "response = requests.get(url)\n",
        "data = response.text.splitlines()\n",
        "\n",
        "# Definición de tokens especiales y clase Lang\n",
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Contar SOS y EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1\n",
        "\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "    return s.strip()\n",
        "\n",
        "# Preparar los datos desde la URL\n",
        "def prepareData(lang1, lang2, lines):\n",
        "    pairs = [[normalizeString(s) for s in l.split('\\t')[:2]] for l in lines]\n",
        "    input_lang = Lang(lang1)\n",
        "    output_lang = Lang(lang2)\n",
        "    pairs = [pair for pair in pairs if len(pair) == 2]\n",
        "\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "\n",
        "    print(f\"Palabras contadas: {input_lang.name} {input_lang.n_words}, {output_lang.name} {output_lang.n_words}\")\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "input_lang, output_lang, pairs = prepareData('eng', 'spa', data)\n",
        "\n",
        "# Funciones para transformar las frases en tensores\n",
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1)\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)\n",
        "\n",
        "# Crear DataLoader para entrenar, ajustando las secuencias a la longitud máxima\n",
        "def get_dataloader(batch_size):\n",
        "    input_lang, output_lang, pairs = prepareData('eng', 'spa', data)\n",
        "    n = len(pairs)\n",
        "    input_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
        "    target_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
        "\n",
        "    for idx, (inp, tgt) in enumerate(pairs):\n",
        "        inp_ids = indexesFromSentence(input_lang, inp)[:MAX_LENGTH - 1]  # Truncar si es necesario\n",
        "        tgt_ids = indexesFromSentence(output_lang, tgt)[:MAX_LENGTH - 1]  # Truncar si es necesario\n",
        "        inp_ids.append(EOS_token)\n",
        "        tgt_ids.append(EOS_token)\n",
        "        inp_ids = inp_ids[:MAX_LENGTH]  # Ajustar longitud exacta a MAX_LENGTH\n",
        "        tgt_ids = tgt_ids[:MAX_LENGTH]  # Ajustar longitud exacta a MAX_LENGTH\n",
        "        input_ids[idx, :len(inp_ids)] = inp_ids\n",
        "        target_ids[idx, :len(tgt_ids)] = tgt_ids\n",
        "\n",
        "    train_data = TensorDataset(torch.LongTensor(input_ids).to(device),\n",
        "                               torch.LongTensor(target_ids).to(device))\n",
        "\n",
        "    train_sampler = RandomSampler(train_data)\n",
        "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "    return input_lang, output_lang, train_dataloader\n",
        "\n",
        "\n",
        "# Definición de la arquitectura del Transformer y componentes adicionales\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:, :x.size(1)]\n",
        "        return self.dropout(x)\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        assert d_model % num_heads == 0\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_heads = num_heads\n",
        "        self.d_k = d_model // num_heads\n",
        "\n",
        "        self.W_q = nn.Linear(d_model, d_model)\n",
        "        self.W_k = nn.Linear(d_model, d_model)\n",
        "        self.W_v = nn.Linear(d_model, d_model)\n",
        "        self.W_o = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
        "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
        "        if mask is not None:\n",
        "            attn_scores = attn_scores.masked_fill(mask == 0, -1e4)  # Ajustar el valor para evitar desbordamiento\n",
        "        attn_probs = F.softmax(attn_scores, dim=-1)\n",
        "        output = torch.matmul(attn_probs, V)\n",
        "        return output\n",
        "\n",
        "    def split_heads(self, x):\n",
        "        batch_size, seq_length, d_model = x.size()\n",
        "        return x.view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1, 2)\n",
        "\n",
        "    def combine_heads(self, x):\n",
        "        batch_size, _, seq_length, d_k = x.size()\n",
        "        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.d_model)\n",
        "\n",
        "    def forward(self, Q, K, V, mask=None):\n",
        "        Q = self.split_heads(self.W_q(Q))\n",
        "        K = self.split_heads(self.W_k(K))\n",
        "        V = self.split_heads(self.W_v(V))\n",
        "\n",
        "        attn_output = self.scaled_dot_product_attention(Q, K, V, mask)\n",
        "        output = self.W_o(self.combine_heads(attn_output))\n",
        "        return output\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, d_model, d_ff):\n",
        "        super(FeedForward, self).__init__()\n",
        "        self.linear1 = nn.Linear(d_model, d_ff)\n",
        "        self.linear2 = nn.Linear(d_ff, d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear2(F.relu(self.linear1(x)))\n",
        "\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
        "        self.feed_forward = FeedForward(d_model, d_ff)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        attn_output = self.self_attn(x, x, x, mask)\n",
        "        x = self.norm1(x + self.dropout(attn_output))\n",
        "        ff_output = self.feed_forward(x)\n",
        "        x = self.norm2(x + self.dropout(ff_output))\n",
        "        return x\n",
        "\n",
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
        "        self.cross_attn = MultiHeadAttention(d_model, num_heads)\n",
        "        self.feed_forward = FeedForward(d_model, d_ff)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.norm3 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, enc_output, src_mask, tgt_mask):\n",
        "        attn_output = self.self_attn(x, x, x, tgt_mask)\n",
        "        x = self.norm1(x + self.dropout(attn_output))\n",
        "        attn_output = self.cross_attn(x, enc_output, enc_output, src_mask)\n",
        "        x = self.norm2(x + self.dropout(attn_output))\n",
        "        ff_output = self.feed_forward(x)\n",
        "        x = self.norm3(x + self.dropout(ff_output))\n",
        "        return x\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.encoder_embedding = nn.Embedding(src_vocab_size, d_model)\n",
        "        self.decoder_embedding = nn.Embedding(tgt_vocab_size, d_model)\n",
        "        self.positional_encoding = PositionalEncoding(d_model, dropout, max_seq_length)\n",
        "\n",
        "        self.encoder_layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
        "        self.decoder_layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
        "\n",
        "        self.fc = nn.Linear(d_model, tgt_vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def generate_mask(self, src, tgt):\n",
        "        src_mask = (src != 0).unsqueeze(1).unsqueeze(2)\n",
        "        tgt_mask = (tgt != 0).unsqueeze(1).unsqueeze(3)\n",
        "        seq_length = tgt.size(1)\n",
        "        nopeak_mask = (1 - torch.triu(torch.ones(1, seq_length, seq_length), diagonal=1)).bool().to(src.device)\n",
        "        tgt_mask = tgt_mask & nopeak_mask\n",
        "        return src_mask, tgt_mask\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        src_mask, tgt_mask = self.generate_mask(src, tgt)\n",
        "        src_embedded = self.dropout(self.positional_encoding(self.encoder_embedding(src)))\n",
        "        tgt_embedded = self.dropout(self.positional_encoding(self.decoder_embedding(tgt)))\n",
        "\n",
        "        enc_output = src_embedded\n",
        "        for enc_layer in self.encoder_layers:\n",
        "            enc_output = enc_layer(enc_output, src_mask)\n",
        "\n",
        "        dec_output = tgt_embedded\n",
        "        for dec_layer in self.decoder_layers:\n",
        "            dec_output = dec_layer(dec_output, enc_output, src_mask, tgt_mask)\n",
        "\n",
        "        output = self.fc(dec_output)\n",
        "        return output\n",
        "\n",
        "# Función de entrenamiento con Early Stopping\n",
        "def train_with_early_stopping(dataloader, model, n_epochs, learning_rate, patience, min_delta):\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "    scaler = GradScaler()\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    counter = 0\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for input_tensor, target_tensor in dataloader:\n",
        "            input_tensor, target_tensor = input_tensor.to(device), target_tensor.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with autocast():\n",
        "                output = model(input_tensor, target_tensor[:, :-1])\n",
        "                output = output.view(-1, output.size(-1))\n",
        "                target = target_tensor[:, 1:].contiguous().view(-1)\n",
        "                loss = criterion(output, target)\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        avg_loss = total_loss / len(dataloader)\n",
        "        print(f\"Epoch {epoch + 1}, Loss: {avg_loss:.4f}\")\n",
        "\n",
        "        # Early Stopping logic\n",
        "        if avg_loss < best_val_loss - min_delta:\n",
        "            best_val_loss = avg_loss\n",
        "            counter = 0\n",
        "        else:\n",
        "            counter += 1\n",
        "            print(f\"No improvement in loss for {counter} epochs\")\n",
        "            if counter >= patience:\n",
        "                print(\"Early stopping triggered\")\n",
        "                break\n",
        "\n",
        "# Hiperparámetros\n",
        "src_vocab_size = input_lang.n_words\n",
        "tgt_vocab_size = output_lang.n_words\n",
        "d_model = 256\n",
        "num_heads = 8\n",
        "num_layers = 3\n",
        "d_ff = 512\n",
        "max_seq_length = MAX_LENGTH\n",
        "dropout = 0.1\n",
        "\n",
        "# Inicializar el modelo\n",
        "transformer = Transformer(src_vocab_size, tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout).to(device)\n",
        "\n",
        "# Entrenamiento con Early Stopping\n",
        "train_dataloader = get_dataloader(256)[2]  # Tamaño de batch optimizado para A100\n",
        "train_with_early_stopping(train_dataloader, transformer, n_epochs=20, learning_rate=0.0001, patience=2, min_delta=0.1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TnTkS526Mr7r",
        "outputId": "854fe58c-6d30-48b1-ca27-d581dae31733"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usando dispositivo: cuda\n",
            "Palabras contadas: eng 13797, spa 26924\n",
            "Palabras contadas: eng 13797, spa 26924\n",
            "Epoch 1, Loss: 5.3439\n",
            "Epoch 2, Loss: 3.9159\n",
            "Epoch 3, Loss: 3.3044\n",
            "Epoch 4, Loss: 2.8875\n",
            "Epoch 5, Loss: 2.5774\n",
            "Epoch 6, Loss: 2.3373\n",
            "Epoch 7, Loss: 2.1471\n",
            "Epoch 8, Loss: 1.9877\n",
            "Epoch 9, Loss: 1.8557\n",
            "Epoch 10, Loss: 1.7394\n",
            "Epoch 11, Loss: 1.6372\n",
            "Epoch 12, Loss: 1.5472\n",
            "No improvement in loss for 1 epochs\n",
            "Epoch 13, Loss: 1.4637\n",
            "Epoch 14, Loss: 1.3914\n",
            "No improvement in loss for 1 epochs\n",
            "Epoch 15, Loss: 1.3249\n",
            "Epoch 16, Loss: 1.2629\n",
            "No improvement in loss for 1 epochs\n",
            "Epoch 17, Loss: 1.2070\n",
            "Epoch 18, Loss: 1.1544\n",
            "No improvement in loss for 1 epochs\n",
            "Epoch 19, Loss: 1.1072\n",
            "No improvement in loss for 2 epochs\n",
            "Early stopping triggered\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, sentence, input_lang, output_lang, max_length=MAX_LENGTH):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # Convertir la frase de entrada a tensores\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence).to(device)\n",
        "        target_tensor = torch.LongTensor([[SOS_token]]).to(device)  # Comenzamos con el token de inicio (SOS)\n",
        "\n",
        "        for _ in range(max_length):\n",
        "            # Generar la predicción\n",
        "            output = model(input_tensor, target_tensor)\n",
        "            topv, topi = output[:, -1].topk(1)  # Selecciona la palabra con la mayor probabilidad\n",
        "            predicted_token = topi.item()\n",
        "\n",
        "            # Si el modelo predice el token de fin (EOS), terminamos la generación\n",
        "            if predicted_token == EOS_token:\n",
        "                break\n",
        "\n",
        "            # Añadir el token predicho a la secuencia de salida\n",
        "            target_tensor = torch.cat([target_tensor, topi.detach()], dim=1)\n",
        "\n",
        "        # Decodificar los tokens de salida en palabras\n",
        "        decoded_words = [output_lang.index2word[token.item()] for token in target_tensor[0][1:]]\n",
        "    return ' '.join(decoded_words)\n",
        "\n",
        "# Función para evaluar múltiples oraciones\n",
        "def evaluateMultiple(model, sentences, input_lang, output_lang):\n",
        "    for sentence in sentences:\n",
        "        translation = evaluate(model, sentence, input_lang, output_lang)\n",
        "        print(f\"Input: {sentence}\")\n",
        "        print(f\"Output: {translation}\\n\")\n",
        "\n",
        "\n",
        "example_sentences = [\n",
        "    \"i am happy\",\n",
        "    \"she is reading\",\n",
        "    \"you are my friend\",\n",
        "    \"he is going to school\",\n",
        "    \"we are playing\",\n",
        "    \"they are learning\",\n",
        "    \"it is raining\",\n",
        "    \"this is my book\",\n",
        "    \"i love you\",\n",
        "    \"can you help me\"\n",
        "]\n",
        "\n",
        "# Evaluar las oraciones de ejemplo\n",
        "evaluateMultiple(transformer, example_sentences, input_lang, output_lang)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUoBuzKWO91T",
        "outputId": "0d8cd5a8-b047-44cf-92e5-d6982144d66c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: i am happy\n",
            "Output: feliz .\n",
            "\n",
            "Input: she is reading\n",
            "Output: leyendo .\n",
            "\n",
            "Input: you are my friend\n",
            "Output: mi amigo .\n",
            "\n",
            "Input: he is going to school\n",
            "Output: al colegio .\n",
            "\n",
            "Input: we are playing\n",
            "Output: jugando jugando jugando .\n",
            "\n",
            "Input: they are learning\n",
            "Output: aprendiendo a aprender .\n",
            "\n",
            "Input: it is raining\n",
            "Output: lloviendo lloviendo .\n",
            "\n",
            "Input: this is my book\n",
            "Output: es mi libro .\n",
            "\n",
            "Input: i love you\n",
            "Output: que tu .\n",
            "\n",
            "Input: can you help me\n",
            "Output: ayudarme a ayudarme ?\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conclusiones\n",
        "\n",
        "- Los resultados del modelo muestran traducciones que capturan la idea general, pero son incompleta o  repetitivas. Esto sugiere que el modelo puede estar limitado por un conjunto de datos insuficiente o un entrenamiento incompleto.\n",
        "- Mejorar el entrenamiento y ajustar el preprocesamiento podrían aumentar significativamente la calidad de las traducciones."
      ],
      "metadata": {
        "id": "7hzFY1EuRNkk"
      }
    }
  ]
}